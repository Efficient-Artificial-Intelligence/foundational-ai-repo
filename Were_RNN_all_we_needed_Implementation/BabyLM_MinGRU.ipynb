{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30805,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Implementation of MinGRU**","metadata":{}},{"cell_type":"markdown","source":"# **Sequential Mode**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nclass MinGRUinSequentialMode:\n    def __init__(self, input_size, hidden_size):\n        self.hidden_size = hidden_size\n\n        # Initialize weights\n        self.Wz = np.random.randn(input_size, hidden_size) * 0.01  # Update gate weights\n        self.Wh = np.random.randn(input_size, hidden_size) * 0.01  # Hidden state weights\n        self.Uz = np.random.randn(hidden_size, hidden_size) * 0.01  # Update gate recurrent weights\n        self.Uh = np.random.randn(hidden_size, hidden_size) * 0.01  # Hidden state recurrent weights\n\n        # Initialize biases\n        self.bz = np.zeros((1, hidden_size))\n        self.bh = np.zeros((1, hidden_size))\n\n    def forward(self, x_t, h_prev):\n        # Update gate\n        z_t = self.sigmoid(np.dot(x_t, self.Wz) + np.dot(h_prev, self.Uz) + self.bz)\n\n        # Candidate hidden state\n        h_tilde = np.tanh(np.dot(x_t, self.Wh) + np.dot(h_prev, self.Uh) + self.bh)\n\n        # New hidden state\n        h_t = (1 - z_t) * h_prev + z_t * h_tilde\n\n        return h_t\n\n    def sigmoid(self, x):\n        return 1 / (1 + np.exp(-x))\n\n# Example usage\ninput_size = 3   # Size of input vector\nhidden_size = 2  # Size of hidden state\n\nmin_gru = MinGRUinSequentialMode(input_size, hidden_size)\nh_prev = np.zeros((1, hidden_size))  # Initial hidden state\nx_t = np.random.randn(5, input_size)  # Current input\n\n# Forward pass\nh_t = min_gru.forward(x_t, h_prev)\nprint(\"New hidden state:\", h_t)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T20:46:13.964754Z","iopub.execute_input":"2024-12-03T20:46:13.965115Z","iopub.status.idle":"2024-12-03T20:46:13.998533Z","shell.execute_reply.started":"2024-12-03T20:46:13.965087Z","shell.execute_reply":"2024-12-03T20:46:13.997752Z"}},"outputs":[{"name":"stdout","text":"New hidden state: [[-0.00063065  0.00440903]\n [ 0.01602061 -0.00444691]\n [-0.00231247 -0.00320737]\n [-0.0114797  -0.00222481]\n [ 0.01844214  0.00330333]]\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"# **Parallel Mode**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nclass MinGRUinParallelMode:\n    def __init__(self, input_size, hidden_size):\n        self.hidden_size = hidden_size\n\n        # Initialize weights\n        self.Wz = np.random.randn(input_size, hidden_size) * 0.01  # Update gate weights\n        self.Wh = np.random.randn(input_size, hidden_size) * 0.01  # Hidden state weights\n        self.Uz = np.random.randn(hidden_size, hidden_size) * 0.01  # Update gate recurrent weights\n        self.Uh = np.random.randn(hidden_size, hidden_size) * 0.01  # Hidden state recurrent weights\n\n        # Initialize biases\n        self.bz = np.zeros((1, hidden_size))\n        self.bh = np.zeros((1, hidden_size))\n\n    def forward(self, x_seq):\n        # Initialize hidden states\n        h_states = np.zeros((x_seq.shape[0], self.hidden_size))\n\n        for t in range(x_seq.shape[0]):\n            if t == 0:\n                h_prev = np.zeros((1, self.hidden_size))  # Initial hidden state\n            else:\n                h_prev = h_states[t-1:t]  # Previous hidden state\n\n            # Update gate\n            z_t = self.sigmoid(np.dot(x_seq[t], self.Wz) + np.dot(h_prev, self.Uz) + self.bz)\n\n            # Candidate hidden state\n            h_tilde = np.tanh(np.dot(x_seq[t], self.Wh) + np.dot(h_prev, self.Uh) + self.bh)\n\n            # New hidden state\n            h_states[t] = (1 - z_t) * h_prev + z_t * h_tilde\n\n        return h_states\n\n    def parallel_scan(self, x_seq):\n        n = x_seq.shape[0]\n        h_states = np.zeros((n, self.hidden_size))\n\n        # Step 1: Calculate hidden states in parallel\n        for t in range(n):\n            if t == 0:\n                h_states[t] = np.zeros((self.hidden_size,))  # Initial hidden state\n            else:\n                h_prev = h_states[t-1]  # Previous hidden state\n\n            z_t = self.sigmoid(np.dot(x_seq[t], self.Wz) + np.dot(h_states[t-1], self.Uz) + self.bz)\n            h_tilde = np.tanh(np.dot(x_seq[t], self.Wh) + np.dot(h_states[t-1], self.Uh) + self.bh)\n            h_states[t] = (1 - z_t) * h_states[t-1] + z_t * h_tilde\n\n        return h_states\n\n    def sigmoid(self, x):\n        return 1 / (1 + np.exp(-x))\n\n# Example usage\ninput_size = 3   # Size of input vector\nhidden_size = 2  # Size of hidden state\n\nmin_gru = MinGRUinParallelMode(input_size, hidden_size)\nx_seq = np.random.randn(5, input_size)  # Sequence of inputs with 5 time steps\n\n# Forward pass with parallel scan\nh_states = min_gru.parallel_scan(x_seq)\nprint(\"Hidden states:\\n\", h_states)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T20:46:23.210006Z","iopub.execute_input":"2024-12-03T20:46:23.210510Z","iopub.status.idle":"2024-12-03T20:46:23.227148Z","shell.execute_reply.started":"2024-12-03T20:46:23.210459Z","shell.execute_reply":"2024-12-03T20:46:23.226233Z"}},"outputs":[{"name":"stdout","text":"Hidden states:\n [[-0.00541459  0.0037567 ]\n [-0.00131788  0.0039851 ]\n [ 0.00120119  0.00659064]\n [ 0.00329749  0.00253187]\n [-0.00310563  0.00456795]]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"# **BabyLM from MinGRU**","metadata":{}},{"cell_type":"code","source":"import numpy as np\n\nclass BabyLMwithMinGRU:\n    def __init__(self, vocab_size, embedding_size, hidden_size):\n        self.vocab_size = vocab_size\n        self.embedding_size = embedding_size\n        self.hidden_size = hidden_size\n\n        # Embedding layer\n        self.embedding = np.random.randn(vocab_size, embedding_size) * 0.01\n\n        # MinGRU Layer\n        self.min_gru = MinGRUinParallelMode(embedding_size, hidden_size)\n\n        # Output layer\n        self.Wo = np.random.randn(hidden_size, vocab_size) * 0.01  # Output weights\n        self.bo = np.zeros((1, vocab_size))  # Output biases\n\n    def forward(self, input_seq):\n        # Step 1: Get the embeddings of the input sequence\n        embedded_seq = self.embedding[input_seq]\n\n        # Step 2: Pass the embedded sequence through the MinGRU\n        h_states = self.min_gru.parallel_scan(embedded_seq)\n\n        # Step 3: Compute the logits (pre-softmax output)\n        logits = np.dot(h_states, self.Wo) + self.bo\n\n        return logits\n\n    def predict(self, input_seq):\n        # Forward pass\n        logits = self.forward(input_seq)\n\n        # Softmax to get probabilities of the next word in the sequence\n        probabilities = self.softmax(logits[-1])\n\n        # Return the index of the word with the highest probability (next word)\n        return np.argmax(probabilities)\n\n    def softmax(self, x):\n        exp_x = np.exp(x - np.max(x))  # For numerical stability\n        return exp_x / np.sum(exp_x)\n\nclass MinGRUinParallelMode:\n    def __init__(self, input_size, hidden_size):\n        self.hidden_size = hidden_size\n\n        # Initialize weights\n        self.Wz = np.random.randn(input_size, hidden_size) * 0.01\n        self.Wh = np.random.randn(input_size, hidden_size) * 0.01\n        self.Uz = np.random.randn(hidden_size, hidden_size) * 0.01\n        self.Uh = np.random.randn(hidden_size, hidden_size) * 0.01\n\n        # Initialize biases\n        self.bz = np.zeros((1, hidden_size))\n        self.bh = np.zeros((1, hidden_size))\n\n    def forward(self, x_seq):\n        n = x_seq.shape[0]\n        h_states = np.zeros((n, self.hidden_size))\n\n        for t in range(n):\n            if t == 0:\n                h_prev = np.zeros((1, self.hidden_size))\n            else:\n                h_prev = h_states[t-1:t]\n\n            z_t = self.sigmoid(np.dot(x_seq[t], self.Wz) + np.dot(h_prev, self.Uz) + self.bz)\n            h_tilde = np.tanh(np.dot(x_seq[t], self.Wh) + np.dot(h_prev, self.Uh) + self.bh)\n            h_states[t] = (1 - z_t) * h_prev + z_t * h_tilde\n\n        return h_states\n\n    def parallel_scan(self, x_seq):\n        n = x_seq.shape[0]\n        h_states = np.zeros((n, self.hidden_size))\n\n        for t in range(n):\n            if t == 0:\n                h_states[t] = np.zeros((self.hidden_size,))\n            else:\n                h_prev = h_states[t-1]\n\n            z_t = self.sigmoid(np.dot(x_seq[t], self.Wz) + np.dot(h_states[t-1], self.Uz) + self.bz)\n            h_tilde = np.tanh(np.dot(x_seq[t], self.Wh) + np.dot(h_states[t-1], self.Uh) + self.bh)\n            h_states[t] = (1 - z_t) * h_states[t-1] + z_t * h_tilde\n\n        return h_states\n\n    def sigmoid(self, x):\n        return 1 / (1 + np.exp(-x))\n\n# Example usage with text\ndef create_vocabulary(texts):\n    # Create a vocabulary from the input texts\n    all_words = ' '.join(texts).lower().split()\n    unique_words = sorted(set(all_words))\n    \n    # Create word to index and index to word mappings\n    word_to_idx = {word: idx for idx, word in enumerate(unique_words)}\n    idx_to_word = {idx: word for word, idx in word_to_idx.items()}\n    \n    return word_to_idx, idx_to_word\n\n# Example texts\ntexts = [\n    \"the quick brown fox jumps over the lazy dog\",\n    \"a journey of a thousand miles begins with a single step\",\n    \"to be or not to be that is the question\"\n]\n\n# Create vocabulary\nword_to_idx, idx_to_word = create_vocabulary(texts)\nvocab_size = len(word_to_idx)\n\n# Hyperparameters\nembedding_size = 10\nhidden_size = 20\n\n# Instantiate BabyLM\nbaby_lm = BabyLMwithMinGRU(vocab_size, embedding_size, hidden_size)\n\n# Prepare input sequence\nexample_text = \"the quick brown fox\"\ninput_words = example_text.lower().split()\ninput_seq = np.array([word_to_idx[word] for word in input_words])\n\n# Predict the next word\nnext_word_idx = baby_lm.predict(input_seq)\nnext_word = idx_to_word[next_word_idx]\n\nprint(\"Input sequence:\", example_text)\nprint(\"Vocabulary size:\", vocab_size)\nprint(\"Predicted next word:\", next_word)\nprint(\"Predicted next word index:\", next_word_idx)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-03T20:47:22.560767Z","iopub.execute_input":"2024-12-03T20:47:22.561379Z","iopub.status.idle":"2024-12-03T20:47:22.578222Z","shell.execute_reply.started":"2024-12-03T20:47:22.561345Z","shell.execute_reply":"2024-12-03T20:47:22.577394Z"}},"outputs":[{"name":"stdout","text":"Input sequence: the quick brown fox\nVocabulary size: 24\nPredicted next word: jumps\nPredicted next word index: 8\n","output_type":"stream"}],"execution_count":5}]}
